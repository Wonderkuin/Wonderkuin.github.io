# Unity 2017 游戏优化

---

# 第一章 研究性能问题

```
目标

方面：
剧情 玩法 画面流畅 数据可靠 用户输入响应 最终文件大小

问题：
低帧率 卡顿 崩溃 输入延迟 加载时间长 不一致的运行时 物理引擎故障 电池消耗过高

理想目标：
最大化利用可用资源，节省计算机资源越多，越不容易出现瓶颈，越容易实现玩法。

最低要求：
确保没有资源不会导致性能瓶颈，优先级最高的任务得到优先执行，没有延迟和卡顿。

保持平衡：
兼顾开发效率，少引入bug，不要过早优化。
```

```
Profiler

指令注入 instrumentation
通过观察目标函数的调用行为，在哪里分配了多少内存，来密切观察
应用程序的内部工作情况。
但是会带来性能损耗。有时会导致严重的不一致行为

基准分析 benchmarking
开始分析代码前，先对应用程序进行体验，在性能变差时持续关注一段时间
关注 渲染帧率 总体内存消耗 CPU活动的行为方式（峰值） CPU GPU温度
从长远看，会节省大量时间

Unity Editor计算操作结果的速度有时候比独立应用程序快很多
这在处理序列化数据（音频 预制块 Scriptable Object ）时很常见
因为编辑器将缓存以前导入的数据，能更快访问


Record
小红按钮 记录所分析的数据
不记录就没有可分析数据了

DeepProfile
普通分析只记录Unity回调，Awake Start Update FixedUpdate
深度分析会导致运行时注入成本更大的多，要使用大量内存
因此在大型项目中，深度分析甚至不可能

Save
一次只能保存300帧，通常也够了


最佳方法
良好的代码实践和项目资源管理会使性能问题的根源查找变得简单
唯一的真正问题是如何改进代码
软件开发的通用目标是：代码简洁 功能丰富 快速
实现两个就很难了
性能分析只是手段而非目的
适用于任何Unity项目的检查：
验证目标脚本是否出现在场景中
验证脚本在场景中出现的次数是否正确
验证事件的正确顺序
最小化正在进行的代码更改
尽量减少内部干扰
尽量减少外部干扰

注意：Unity的日志打印非常昂贵
协程的yield 非常难以调试

UnityEngine.Profiling.Profiler.BeginSample()
UnityEngine.Profiling.Profiler.EndSample()
在运行时激活和禁用分析功能的分隔符方法

Profiler
根据300帧的内容自动调整垂直轴，小的峰值也可能变化
看起来问题严重，事实上并不一定存在性能问题
要看水平线的 ms/FPS
```

---

# 第二章 脚本策略

```
GetComponent 速度差别
GetComponent<T>() 优于 GetComponent(typeof(T)) 优于 GetComponent(string)


移除空的回调
Awake Start Update


缓存组件引用


共享计算输出
注意：不要预先优化，除非已经证明是性能问题


AI可以不每一帧调用


Coroutine
启用协程会带来额外开销，大概是普通函数调用的三倍
还会分配内存，每次yield都带来相同的开销
协程会在包含它的GameObejct变成不活动时停止
GameObject再次活动，协程也不会重新启动

Invoke
可以用Invoke替代协程
InvokeRepeating("ProcessAI", 0f, _aiProcssDelay);
Invoke独立于GameObject和MonoBehaviour的状态
销毁方法一，调用CancelInvoke
方法二，销毁关联的MonoBehaivour或者它的父GameObject
invoke略微快于协程


GameObject空引用检查
GameObject和MonoBehaviour是特殊对象
在内存中有两个表示，一个是托管的，一个是Native的
数据在这两个空间移动造成额外的cpu开销和内存分配（可能）
if (gameObject != null) {}
if (!System.Object.ReferenceEquals(gameObject, null)){}
下面的更快，但好处很微小
任何一个空检查仍然只消耗纳秒
如果有大量的空检查，才提现处区别


避免从GameObject取出字符串属性
还是因为本机-托管桥接
gameObject.tag
gameObject.name
根据组件的类类型来标识对象，以及标识不涉及字符串对象的值
这样更好，但有时会由于项目的一些原因不好用
gameObject.CompareTag("Player")
这样避免了桥接，没有内存分配，没有垃圾回收
结论：尽可能避免访问name和tag属性，如果需要对标记进行比较
应该使用CompareTag，但是name属性没有对应的方法，因此尽可能
使用tag


使用合适的数据结构
例如：快速找出哪个对象映射到另一个对象 同时还能遍历组。
通常，开发者会使用字典，然后进行迭代。 然而，遍历字典非常慢
这种情况下， 最好同时用列表和字典
插入删除就在字典
迭代就在列表


避免运行时修改Transform的父节点
Unity5.3及以前，Transform像是堆存储，插入删除相对较快
Unity5.4及以后，Transform更像是动态数组存储
因此Unity将Transform按顺序存储，按Hierarchy深度排序
这种策略使得Transform更快的迭代，对物理和动画等子系统非常有利
缺点是更改Transform父节点，必须放入内存缓冲区，根据新的深度重新排序
如果父对象没有预先分配足够的空间容纳子对象，还需要扩展缓冲区
对于较深复杂的GameObject，这需要一些时间
例如：
调用GameObject.Instantiate()，父节点是null，Transform被放在Hierarchy根元素下
由于，根元素下所有的Transform都需要分配一个 缓冲区来存储它当前的子元素以及以后可能添加的子元素，(子元素不需要这样做)
Transform分配了缓冲区, 这时，又设置Transform的父节点，它将丢弃刚才分配的缓冲区
为了避免这种情况，需要将父节点交给Instantiate调用，避免分配缓冲区
另一种方法：
让根Transform预先分配一个更大的缓冲区，这样就不需要在同一帧拓展缓冲区，给它重新指定另一个GameObject到
缓冲区中。这可以通过修改Transform的hierarchyCapacity属性来实现


Transform
position rotation scale会导致大量的矩阵乘法计算
通过父对象生成正确的变换，对象在Hierarchy中的位置越深
计算越多
使用localPosition localRotation localScale的成本相对较小
不需要额外的矩阵乘法
遗憾的是，将数学计算从世界空间更改为本地空间，会使原本简单的问题
变得过于复杂。为了更容易的解决问题，性能的牺牲是值得的
不断更改Transform属性的另一个问题是，会向其他组件（collider Rigidbody Light
Camera）发送内部通知，这些组件也必须进行处理。
在复杂的事件链中， 同一帧多次修改Transform属性很常见
可以放在一个成员变量中，只在帧末尾提交
private bool _positionChanged;
private Vector3 _newPosition;
public void SetPosition(Vector3 position)
{
	_newPosition = position;
	_positionChanged = true;
}
void FixedUpdate()
{
	if (_positionChanged)
	{
		transform.position = _newPosition;
		_positionChanged = false;
	}
}
FixedUpdate确保了不会出现奇怪行为
物理和渲染系统始终与Transform同步


避免使用SendMessage()和GameObject.Find()方法
依赖这两种方法，通常是糟糕的设计，或者是懒惰。
GameObject enemyManagerObj = GameObject.Find("EnemyManager");
enemyManagerObj.SendMessage("AddEnemy", enemy, SendMessageOptions.DontRequireReceiver);
使用GetComponent替代SendMessage
那么，如何替代Find方法？
1 将引用分配给预先存在的对象
	简单方法是使用Unity的序列化系统，纯粹主义者认为这样破坏了封装性
	但它十分有效。
	[SerializeField] private GameObject _enemyPrefab;
	问题：预制体 预制体实例都可以分配给GameObject字段
	如果使用了预制体，会意外的实例化一个新的GameObject
	或者可能对预制体造成改变，这是永久性的
	好处：团队友好
2 静态类
	全局管理器在软件工程领域不受欢迎
	但是单例模式对于管理共享资源或者繁重的数据流量（文件访问，下载，数据解析，消息传递）非常有用。
	public static class StaticEnemyManager {
		private static List<Enemy> _enemies;
		static StaticEnemyManager() {
			_enemies = new List<Enemy>();
		}
	}

	public class EnemyCreatorCompanionComponent : MonoBehaviour {
		[SerializeField] private GameObject _enemyPrefab;
		public void CreateEnemy() {
			StaticEnemyManager.CreateEnemy(_enemyPrefab);
		}
	}
3 单例组件
	public class SingletonComponent<T> : MonoBehaviour where T : SingletonComponent<T> {
		private static T _Instance;
		protected static SingletonComponent<T> _Instance {
			get {
				if (!_Instance) {
					T[] managers = GameObject.FindObjectsOfType(typeof(T)) as T[];
					if (managers != null) {
						if (managers.Length == 1) {
							_Instance = managers[0];
							return _Instance;
						}
						else if (managers.Length > 1) {
							Debug.LogError("Too much");
							for (int i = 0; i < mangers.Length; ++i) {
								T manager = managers[i];
								Destroy(manager.gameObject);
							}
						}
					}
					GameObject go = new GameObject(typeof(T).name, typeof(T));
					_Instance = go.GetComponent<T>();
					DontDestroyOnLoad(_Instance.gameObject);
				}
				return _Instance;
			}
			set {
				_Instance = value as T;
			}
		}
	}

	public class EnemyManagerSingletonComponent : SingletonComponent<EnemyManagerSingletonComponent> {
		public static EnemyManagerSingletonComponent Instance {
			get { return ((EnemyManagerSingletonComponent)_Instance);}
			set { _Instance = value; }
		}
	}
	单例难以删除，最好不要在其他函数的OnDestroy调用单例。或者判断单例是否存活再调用。
4 全局消息传递系统
	这是一个优秀的长期解决方案，可以在应用程序变得越来越复杂时保持通信对象的模块化，解耦和快速。
	1 全局访问
		可以用单例，也可能存在多个实例
	2 任何对象都可以注册，注销为侦听器，来接收特定的消息类型 即Observer设计模式 观察者模式
		应该实现一种方法，使系统在
		可以提供一个通过参数检索消息的方法，并返回一个响应。
		该相应确定侦听器是否应该停止处理消息。以及何时停止处理。
		true意味着这个侦听器已经处理完消息，消息的处理必须停止
		false意味着侦听器未处理消息，消息传递系统应该尝试下一个侦听器
	3 当从其他地方广播给定的消息时，注册对象应该提供一个调用方法
	4 系统应该在合理的时间范围内将消息发送给所有侦听器，但不要同时处理太多请求
	public class Message{
		public string type;
		public Message() { type = this.GetType().Name; }
	}
	public delegate bool MessageHandlerDelegate(Message message);

	private Dictionary<string, List<MessageHandlerDelegate>> _listenerDict;
	public bool AttachListener(System.Type type, MessageHandlerDelegate hangler) {
		if (type == null) {
			Debug.Log("failed");
			return false;
		}

		string msgType = type.Name;
		if (!_listenerDict.ContainsKey(msgType)) {
			_listenerDict.Add(msgType, new List<MessageHandlerDelegate>());
		}
		List<MessageHandlerDelegate> listenerList = _listenerDict[msgType];
		if (listenerList.Contains(handler)) {
			return false;//listener already in list
		}

		listenerList.Add(handler);
		return true;
	}

	private Queue<Message> _messageQueue = new Queue<Message>();
	public bool QueueMessage(Message msg) {
		if (!_listenerDict.ContainsKey(msg.type)) {
			return false;
		}
		_messageQueue.Enqueue(msg);
		return true;
	}

	private const int _maxQueueProcessingTime = 16667;
	private System.Diagnostics.Stopwatch timer = new System.Diagnostics.Stopwatch();

	void Update() {
		timer.Start();
		while (_messageQueue.Count > 0) {
			if (_maxQueueProcessingTime > 0.0f) {
				if (timer.Elapsed.Milliseconds > _maxQueueProcessingTime) {
					timer.Stop();
					return;
				}
			}

			Message msg = _messageQueue.Dequeue();
			if (!TriggerMessage(msg)) {
				Debug.Log("Error");
			}
		}
	}

	public bool TriggerMessage(Message msg) {
		string msgType = msg.type;
		if (!_listenerDict.ContainsKey(msgType)) {
			Debug.Log("no listeners");
			return false;
		}

		List<MessageHandlerDelegate> listenerList = _listenerDict[msgType];

		for (int i = 0; i < listenerList.Count; ++i) {
			if (listenerList[i](msg))
				return true;//message consumed by the delegate
		}

		return true;
	}
	太多了。略


禁用未使用的脚本和对象
1 通过可见性禁用对象
	渲染有优化
		摄像机 视锥剔除
		避免渲染隐藏在其他对象后面的对象 遮挡剔除
	但是不会影响cpu上执行任务的组件，我们必须自己控制这些行为
	OnBecameVisible
	OnBecameInvisible
	注意：多个摄像机，每个摄像机都不可见或可见才会调用
	因为和渲染有关，需要MeshRenderer SkinnedMeshRenderer才行
	Scene的摄像头也会影响调用
2 通过距离禁用对象
	漫游的AI生物，在远处不需要任何操作

使用距离的平方而不是距离

最小化反序列化行为
	Unity序列化主要用于 场景 Prefab ScriptableObjects
	派生自ScriptableObject的资产类型
	会通过YAML格式转换成文本文件
	所有GameObject及其属性都会在序列化预制件或者场景时序列化，包括private protected字段
	构建应用程序时，这些序列化数据会捆绑在大型二进制数据文件中，在Unity内部被称为序列化文件
	在运行时从磁盘读取和反序列化非常慢。
	Resources.Load时发生，由于预制件的每个组件都是序列化的，因此层次结构越深，需要反序列化的数据就越多。
	很深层次结构的预制块，带有许多空GameObject的预制块，这是有问题的。
	对UI来说尤其是问题，UI往往带有更多的组件
	第一次加载耗时，中间加载掉帧
	1 减小序列化对象
		我们的目标应该是是序列化对象尽可能小，或者分割成更小的数据块
	2 异步加载序列化对象
		Resource.LoadAsync
		检测ResourceRequest.isDone
	3 在内存中保存之前加载的序列化对象
		需要权衡内存
	4 将公共数据移入ScriptableObject
		减少了数据量

叠加、异步地加载场景
	SceneManager.LoadScene 快，但是阻塞主线程
	SceneManager.LoadSceneAsync 慢，用户体验好
	检测LoadSceneMode.Additive
	场景可以叠加，分成小的子场景，适当时候异步加载
	此时，可能释放内存，触发GC，有效利用内存非常重要
	SceneManager.UnloadScene 卸载

创建自定义Update层
	成千上万MonoBehaviour同时初始化，同时启用协程，每500ms执行一次
	协程极有可能在同一帧触发 导致CPU峰值
	希望分散Update调用，避免出现峰值
	Update也是本机-托管的桥接，代价较高

	public interface IUpdatable {
		void OnUpdate(float dt);
	}
	public class UpdatableComponent : MonoBehaviour, IUpdatable {
		public virtual void OnUpdate(float dt) {}

		void Start() {
			GameLogic.Instance.RegisterUpdatableObject(this);
			Initialize();
		}

		protected virtual void Initialize() {}//派生类覆盖这个方法

		void OnDestroy() {
			if (GameLogic.Instance.IsActive)
				GameLogic.Instance.DeregisterUpdatableObject(this);
		}
	}
	dt节省了不必要的Time.deltaTime调用
	GameLogic 用数组维护IUpdatable
```

---

# 第三章 批处理的优势

```
Draw Call

准备网格和纹理数据
配置渲染状态Render State
	更改渲染状态 很耗时 因为用于渲染当前对象的纹理再Graphics API中其实
	是一个全局变量，而在并行系统内修改全局变量很难，必须等待所有作业到达
	同一个同步点 (最快的停下等待 最慢的追上 浪费了可用于其他任务的时间)
	到达同步点后，需要重新启动所有并行作业
	因此 请求改变渲染状态的次数越少，Graphics API越能更快地处理请求
	触发渲染状态同步的操作包括但不限于：
		立刻推送一张新纹理到GPU
		修改着色器 照明信息 阴影 透明度 和其他任何图形设置
一旦配置了渲染状态GPU就必须决定绘制哪个网格，使用什么纹理和着色器
	以及基于对象的位置 旋转 缩放，然后发送到GPU绘制
为了使CPU和GPU之间的通信保持活跃，新指令被推入一个名为Command Buffer的队列
	这个队列包含CPU创建的指令，以及GPU每次执行完前面的命令后从中提取的指令
批处理提升此过程的诀窍在于：
	新的Draw Call 不一定意味着必须配置新的渲染状态。如果两个对象共享完全相同的
	渲染状态信息，那么GPU可以立即开始渲染新对象。因为在最后一个对象完成渲染之后，
	还维护着相同的渲染状态，这消除了由于同步渲染状态而浪费的时间，也减少了推入
	Command Buffer中的指令数，减少了 CPU和GPU 的工作负载
```

```
着色器
	减少场景中使用材质的数量，同时提升两个性能
	1 CPU每帧将花费更少的时间生存指令，并传输给GPU
	2 GPU不需要经常停止，重新同步状态的变更

	测试材质越少，性能越高需要
	禁用一些渲染选项，因为它们产生额外Draw Call
	Edit|ProjectSettings|Quality Shadows->DisableShadows或者Fastest
	Edit|ProjectSettings|Player OtherSettings 禁用StaticBatching或者DynamicBatching
	建立空场景，放置八个不同材质的物体
	此时，9个DrawCall，一个材质一个批处理，当前视图背景消耗一个批处理
	将所有物体改为同一个材质，还是9个DrawCall
	遗憾的是，管线渲染不够智能，意识不到我们在写入完全相同的渲染信息。
```

```
FrameDebugger
	bug: 使用天空盒，无法查看不同对象的渲染，只能禁用天空盒
	每一个数字代表一个GraphicsAPI调用，DrawCall只是一种API调用
	任何API调用和DrawCall的开销都差不多，但复杂场景中的大多数API调用都采用DrawCall的形式
	因此最好关注DrawCall最小化，再去担心诸如后期处理效果等API通信开销
```

```
动态批处理
	重要优势
	1 批处理在运行时生成（批处理是动态产生的）
	2 批处理中包含的对象在不同帧之间可能有所不同，
	这取决于哪些网格在主摄像机视图中当前是可见的
	（批处理内容是动态的）
	3 甚至能在场景中运动的对象也可以批处理（对动态对象有效）
	要求
	1 所有网格实例必须使用相同的材质引用
	2 只有ParticleSystem MeshRenderer组件进行动态批处理
	SkinnedMeshRenderer组件和其他可渲染的组件类型不能进行批处理
	3 每个网格至多有300个顶点
	4 着色器使用的顶点属性数不能大于900
	5 所有网格实例要么使用等比缩放，要么使用非等比缩放，但不能两者混用
	6 网格实例应该引用相同的光照纹理文件
	7 材质的着色器不能依赖多个过程
	8 网格实例不能接受实时投影
	9 整个批处理中网格索引的总数有上限，这与所用的GraphicsAPI和平台有关
	解释
	顶点属性
		顶点属性只是网格文件中基于每个顶点的一段信息，每一段通常表示为一组浮点数。
		它包括但不限于
			顶点位置（相对于网格的根）
			法线向量（一个从对象表面指向外面的向量，通常用于光照计算）
			一套或者多套纹理UV坐标（用于定义一张或者多张纹理如何包裹网格）
		甚至可能包括
			每个顶点的颜色信息（通常用于自定义光照或扁平化着色，低多边形风格的对象）
		只有着色器使用的顶点属性总数小于900才能使用动态批处理
		注意：不要看原始数据文件的顶点属性，要看Unity中转化后的属性，MeshFilter可以看Preview
		例子：四个Cube，四个Sphere，材质相同，Cube合并， Sphere不合并
			Cube有8个顶点，每个顶点有位置，法线，UV 3个属性，共24个属性
			Sphere有515个顶点，共1545个顶点属性，因此无法动态合并
			FrameDebugger会显示这个DrawCall为什么不能与前一个合并
	网格缩放
		等比缩放意味着 xyz相同 非等比缩放意味着 至少有一个不同
		负数缩放是一种常用的镜像手段，但是会影响动态批处理。
		负数缩放会产生奇怪的效果，与xyz哪个是负数无关，与负数值的数量是奇数或偶数有关。
		负数缩放也会影响批处理， 如果ABCDE五个，AE可以合并，但是BCD有负数，结果AE无法合并。
	总结
		渲染大量简单网格，动态批处理非常有用。
		可能造成损耗的地方：数百个简单对象，而每个批处理只有几个对象。这时，检测和生成小批处理组的开销
		成本可能比不合并DrawCall更高。
```

```
静态批处理
	内容也是动态的，取决于摄像机是否可见。但只处理static对象
	要求
		静态标记 Batching Static
			不能移动 旋转 缩放
		被静态批处理的网格需要额外的内存
			额外内存需求取决于批处理的网格中复制的次数。
			静态批处理工作时，将所有Batching Static可见网格数据复制到一个更大的
			网格数据缓冲中，并通过一个DrawCall传到管线渲染中，同时忽略原始网格。
			如果所有进行静态批处理的网格各不相同，那么与正常渲染相比，不会增加内存用量
			因为存储网格需要的内存空间量是相同的。
			由于数据是高效复制过来的，会消耗额外内存，数量等于网格数量乘以原始网格大小。
			渲染100个相同对象， 因为变换不同，数据拷贝了100次。
			因此，如果没用对静态批处理，会有严重的内存消耗和性能问题。
		合并到静态批处理中的顶点数量有上限，并随着GraphicsAPI和平台的不同而不同
		网格实例可以来自任何网格数据源，它们必须使用相同的材质引用
	材质引用
		不同材质的网格会划分到各自的静态批处理组，每个组使用不同的材质
		缺点是，静态批处理渲染所有静态网格时，使用的DrawCall数量最多只能等于所需的材质数量
	警告：
		实现批处理的方式是，将网格合并到更大的网格中。
		存在不明显的缺点：
			DrawCall减少了，但不能直接在Stats窗口看到，要在运行时才能看到
			在运行时向场景中引入标记为BatchingStatic的对象，不能自动包含进静态批处理中
		1 静态批处理的Edit模式调试
			需要在Play模式用FrameDebugger调试验证静态批处理是否有效
		2 在运行时实例化静态网格
			Unity不会尝试自动合并新生成的BatchingStatic对象，如果场景是叠加方式加载的
			可以考虑用
			StaticBatchUtility.Combine(GameObject root) 处理root下所有对象
			StaticBatchUtility.Combine(List<GameObject> list, GameObject root) 将list作为root子节点处理
			不会将给定的网格与任何预先存在的静态批处理合并，而是合并这些网格
			注意：如果root不是静态，root下要合并的对象是静态，那么合并后移动了root，合并的对象也不会移动
	总结
		强大但危险，很容易消耗大量内存，还需要大量手动调试和配置，以确保正确生成批处理。
		优势在于可以用于不同形状和巨大尺寸的网格，这是动态批处理无法提供的。
```

```
总结：
	没有银弹 必须测试以证明批处理有效，否则可能是负面效果
```

---

# 第四章 着手处理艺术资源

```
音频

运行时音频处理会成为CPU和内存消耗的重要来源
音频处理得好，没人会注意，糟糕的音频会引起注意。
导致内存和CPU性能低下的原因：
	过度压缩
	过多的音频操作
	过多的活动音频组件
	低效的内存存储方法和访问速度

导入
	加载行为 压缩行为 质量 采样率 是否支持双声道（多通道，通过球面谐波组合音轨）
加载
	Preload Audio Data
		场景初始化期间自动加载，还是在以后加载
	Load In Background
		在完成之前阻塞主线程，还是在后台异步加载
	Load Type
		将什么类型的数据拉入内存，以及一次拉入多少数据

	音频文件的典型用法是将其分配给AudioSource对象的audioCilp属性
		通过AudioSource.Play AudioSource.PlayOneShot 播放
	这种方式分配的每个音频都将在场景初始化期间加载，因为场景包含对这些文件的即时引用
		在需要这些文件之前必须先解析引用。
		这时启用PreloadAudioData时的默认情况。
		如果禁用PreloadAudioData，则会在第一次播放时加载，阻塞主线程
	AudioClip.LoadAudioData可以实现音频加载，但是仍然会阻塞主线程
		启用LoadInBackground，将改为异步，通过AudioClip.loadState查看是否完成
		如果没加载完成就调用播放，声音会有延迟
	AudioClip.UnloadAudioData卸载音频

	现代游戏通常在关卡中实现方便的停止点，以执行加载或者卸载音频数据之类的任务
		例如，几乎不发生任何操作的电梯或长廊，这需要这对特殊情况大量更改，测试

	LoadType选项，指示音频数据如何加载
		DecompressOnLoad
			压缩磁盘文件 加载时解压缩
		CompressInMemory
			压缩磁盘文件 直接拷贝内存 播放时解压缩 牺牲CPU
			适合频繁使用的大型音频文件，或者为了减少内存消耗，牺牲CPU
		Streaming
			缓冲 在运行时加载 解码 播放文件。逐步将文件推过一个小缓冲区，
			在缓冲区一次只存在整个文件的一小部分数据
			内存使用量最小，运行时CPU消耗最大。
			每个播放实例都有自己的缓冲区，导致多次引用音频文件，产生多个副本。
			最好用于定期播放的单实例音频，如背景音乐 环境音效
编码格式与级别
	Compressed
		一般情况都用这种
		格式取决于目标平台
		独立应用程序，其他非移动平台 Ogg Vorbis
		移动平台 MP3
		PSV HEVGA
		XBoxOne XMA
		WebGL AAC
		压缩成本查看需要根据平台切换，ogg压10倍，ADPCM4倍，AAC可能过大
	PCM
		无损，未压缩格式
		用于 极短暂且需要高清晰度的音效
	ADPCM
		压缩会产生相当大的噪声，用于爆炸，碰撞，冲击声音
音频性能增强
	1 最小化活动音源数量
		由于每个播放中的音源消耗特定数量的CPU，因此禁用冗余的音源可以节省CPU周期
		一种方法是限制可以同时播放音频剪辑的实例数。
	2 为3D声音启用强制为单声道
		在立体声音频文件上启用Force to Mono（强制为单声道）会将两个音频通道的数据混合到
		一个通道，文件的总磁盘和内存空间使用量有效降低了一半
		一般不要给二维音效启用此项，但是在两个通道实际相同的3D位置音频剪辑上可以启用此选项，
		以节省一些空间。
	3 重新采样到低频
		可以将音频文件的SampleRate设置为OverrideSampleRate，通过SampleRate设置采样率。
		22050Hz是源于人类语音和古典音乐的一个常见采样率。
		在确定降低之前，最好花时间测试。
	4 考虑所有的压缩格式
		Compressed PCM ADPCM各有优劣，可以对不同文件使用不同编码格式。
	5 注意流媒体
		Streaming加载类型的优点是运行时内存成本低。
		但应该仅限于大型的单例文件，因为它需要运行时硬盘访问。
		使用Streaming时，分层或者转换的音乐剪辑可能会遇到严重问题，最好考虑使用另一个LoadType
		并手动控制加载，卸载。
		还应该避免一次传输多个文件，因为它可能会在磁盘上造成大量缓存丢失，从而打断游戏。
		这就是为什么该选项主要用于背景/环境音效，因为一次只需要一个背景/环境音效。
	6 通过混音器组应用过滤效果以减少重复
		过滤效果可用于修改通过音频源播放的音效，并可通过FilterEffect组件完成。
		每个单独的过滤效果都需要消耗一定的内存和CPU。这是一个很好的方法，可以节省磁盘空间，
		同时保持音频播放的多样性，因为一个文件可通过一组不同的过滤器进行调整，以产生完全不同
		的声音效果。
		由于有额外开销，过度使用过滤器效果会导致性能上的严重后果。更好的方法是利用Unity的音频
		混音器(window/audio mixer)生成通用的过滤效果模板，多个音频源可以引用这些模板，以最小化内存开销
	7 谨慎使用远程内容流
		可以使用Unity通过Web动态加载游戏内容，素材可以通过Unity5的WWW或Unity2017的UnityWebRequest完成
		Unity2017中， UnityWebRequest取代了WWW，使用了新的HLAPI和LLAPI网络层。
		多媒体通过UnityWebRequestMultimedia辅助类发送。
		UnityWebRequestMultimedia.GetAudioClip()创建请求，调用DownloadHandlerAudioClip.GetContent()在
		下载完成后去除音频内容。
		这种方法多次重新获取音频不会导致额外内存分配，智慧返回对最初下载的音频剪辑的引用。
		WWW每次调用生成一个全新的AudioClip对象，如果不需要必须Resources.UnloadAsset()释放它。
	8 考虑用于背景音乐的音频模块 (Audio Module) 文件
		类似于MIDI文件，MIDI的缺点在于声音取决于音频硬件中可用的音库，因此MIDI音乐在不同计算机上听起来可能不同
			相比之下，音轨模块包含高质量PCM样本，无论使用何种音频硬件，都能确保获得相似的体验。
		音频模块文件也称为音轨模块 TrackerModule，是节省大量空间，并且没有任何明显质量损失的绝佳方式。
		Unity中支持的文件拓展名有.it .s3m .xm .mod
		在普通的音频格式中，音轨模块是以位流的形式读取的，必须在运行时解码以生成特定的声音，而音轨模块
		包含许多小的，高质量的样本，并将整个音轨组织成类似于音乐表的形式；定义每个样本的播放时间，位置，音量，
		音高，特效。这样可以在保持高质量采样的同时显著节省占用的空间大小。因此，如果有机会为音乐文件使用音轨
		模块版本，就应该好好探索一番。
		开源软件 ：MilkyTracker OpenMPT
```

```
纹理文件
	纹理：只是简单的图像文件，一个颜色数据的大列表，以告知插值程序，图像的每个像素应该是什么颜色
	精灵：是网格的2D等价物，通常只是一个四边形（一对三角形合并成的长方形网格）用于渲染面向当前相机的平面。
	精灵表：一个大纹理文件内大量独立图像的集合，通常用于包含2D角色动画。可用用工具切分，如Sprite Atlas
	网格和精灵都是用纹理，将图像渲染到它的表面。纹理图像通常有Photoshop，GIMP等工具生成，
	导入项目中，在运行时这些文件加载进内存，推送到GPU的显存，并在给定DrawCall期间，由着色器渲染到目标精灵或网格上。

	纹理压缩格式
		texture type
			要设置该选项以明确纹理的目的
			NormalMap Sprite Lightmap
			特别是Advanced下拉框的类型
		可用常用格式导入纹理文件 jpg png
			但应用程序中内置的实际压缩格式可根据给定平台的GPU，从很多不通到纹理压缩格式中
			选择理想适配的一种
			这些格式的设置：
				描述每个通道的不同位数 （位数越多，颜色越多）
				红色通道可能使用比绿色通道更多的位数
				用于所有通道的总位数 （更大的纹理，更多的磁盘和内存消耗）
				是否包括Alpha通道
				打包数据的不同方式
					这允许GPU进行高效内存访问，如果选择了错误的包装类型，访问效率非常低
			Compression纹理导入选择如下的一个选项：
				None 不压缩
				Low Quality
				Normal Quality
				High Quality
	纹理性能增强
		1 减小纹理的大小
			为了确定是否在内存带宽存在瓶颈，一个简单的测试是：
			降低游戏中最丰富，最大的纹理文件的分辨率，并重启场景。如果帧率突然提高，那么应用程序很可能
			受到了纹理吞吐量的限制。
		2 谨慎使用MipMap
			MipMap解决了两个问题：
				微小的细节不值得用大贴图
				混叠现象，图像在缩小时因为采样率不够，如果是线，就表现为断线，如果纹理复杂，就表现为杂乱。
			纹理只有需要在距离摄像机很远或很近的地方渲染时，MipMap才有用。
			不要在离摄像机相对固定的纹理上使用MipMap
		3 从外部管理分辨率的降低
			Unity可用直接使用PSD TIFF文件生成纹理，缩小图像比例可能会造成混叠失真。
			要习惯性避免直接用PSD和TIFF文件，在Unity使用导出的文件。
		4 调整 Anisotropic 各向异性 Filtering 级别
			各向异性过滤使用了过滤 当视角变化导致3D物体表面倾斜时造成的纹理错误
			各向异性是一项在非常倾斜的角度观察纹理时，提升纹理品质的特性。
			无论是否启用各向异性，靠近相机的线都相当清晰，但与相机距离边远则发生变化。
			应用于纹理的各向异性筛选的强度，可通过AnisoLevel设置逐个手动更改
			也可以在Edit|Project|Quality设置内用AnisotropicTextures选项全局启用/禁用
			于MipMap很像，AnisotropicFiltering很昂贵，有时没有必要使用。
			如果场景中的一些纹理肯定不会以倾斜的角度看到，例如
			远处的背景对象，UI元素，公告板 粒子效果纹理
			就可以安全的禁用Anisotropic Filtering来节省开销
		5 使用图集
			每种独特的材质都需要额外的DrawCall，但是每种材质只支持单一的主纹理。当然，它们也可以支持
			多个二级纹理，比如法线纹理和发射纹理。然而，将多个主纹理合并到一个大的纹理中，渲染共享
			这个纹理的对象时，可最小化所使用的DrawCall数量
			16Textures 16Materials 16DrawCalls 合并图集后
			1Textures 1Materials 1DrawCalls
			需要做的额外工作是修改网格或精灵对象的UV坐标，只采样大纹理文件中所需要的部分，但好处很明显。
			如果程序的瓶颈在CPU，则减少DrawCall就会降低CPU工作负载，提升帧率。
			假设合并纹理文件的分辨率和所有合并的图像相同，就不会有品质损失，而内存消耗也会相同。
				注意，由于推送到GPU的数据是一样的，因此图集不会减少内存带宽消耗。
			提示：图集只是当所有给定的纹理需要相同着色器时采用的一种方法，如果一些纹理需要通过着色器应用
				独立的图形效果，它们就必须分离到自己的材质中，并在单独的组打包图集。
			图集是必不可少的技术，不一定要用于2D图形和UI元素。如果创建了很多低分辨率的纹理，则可用将此技术
				应用到3D网格上。如果3D游戏具有简单纹理的分辨率，或者是扁平着色的低多边形网格，都可以这种使用图集。

			然而，由于动态批处理效果只影响非动画的网格 MeshRenderer而不是SkinnedMeshRenderer，因此不要将动画
				角色的纹理合并到图集。由于它们是动画的，GPU需要将每个对象的骨骼乘以当前的动画状态的变换。这意味着需要为
				每个角色进行独立的计算，不管它们是否共享了材质，该计算都将导致额外的DrawCall。

			缺点：主要是开发时间和工作流成本。要彻底检查现有的项目才能使用图集，这需要花费大量的精力，只是为了辨别是否
				值得使用图集就需要做很多工作。此外，还需要注意纹理文件的生成，可能太大。
			如果DrawCall太多，可用尝试用图集。
		6 调整非方形纹理的压缩率
			纹理通常是正方形，2的n次幂的格式保存。
			避免不是这种格式的纹理。
		7 Sparse Texture
			也叫 Mega-Texture Tiled-Texture 提供了一种运行时从磁盘传输纹理数据流的方式。
			将许多纹理组合成一个巨大的纹理文件，这个文件超级大，无法作为一个纹理文件加载到图形内存中。
			类似于图集，只是包含纹理的文件非常大，并且包含相当多的颜色细节。
			比如，32768x32768像素 每个像素32位 (占用4GB)
			理念是，通过手动选择要从磁盘中动态加载的小片段纹理，在游戏中需要它们以前将它们从磁盘中取出，
			来节省大量的运行时内存和内存带宽。
			主要成本是文件大小需求和潜在的连续磁盘访问。
			这种技术的其他成本是可以克服的，但是通常需要大量的场景准备工作。
			在游戏行业，这是一种高度专业化的技术，但没有被广泛采用，部分原因是它需要专业的硬件和平台支持。
			另一部分原因是它难以完美实现。
		8 程序化材质
			Substances 在运行时通过使用自定义数学公式混合小型高质量的纹理样本，通过程序化方式生成纹理的手段。
			目标是：在初始化期间以额外的运行时内存和CPU处理为代价，极大地减少应用程序的磁盘占用，以便通过数学
			操作而不是静态颜色数据来生成纹理。
			纹理文件有时是游戏项目中最大的磁盘空间消耗者，下载很慢，程序化材质允许牺牲一些初始化和运行时处理能力，以换取更快的
			下载。这对于想要通过图形逼真程度竞争的移动游戏很重要。
		9 异步纹理上传
			Read/Write Enable 默认是禁用的，禁用的好处是纹理可用Asynchronous Texture Uploading特性
			: 纹理会从磁盘异步上传到RAM 且当GPU需要纹理数据时，传输发生在渲染线程而不是主线程
			纹理会推送到环形缓冲区中，一旦缓冲区中包含新数据，数据就会持续不断地推送到GPU
			如果没有新数据，就提前退出处理并等待，直到请求新的纹理数据。
			最终，这减少了每帧准备渲染状态所花费的时间，节省了主CPU
			开启 Read/Write Enable 是告知Unity，我们要随时更改该纹理，暗示着GPU需要随时刷新对它的访问
			仅适用于明确导入到Unity，构建时存在的纹理。因为需要打包到可流式传输的特殊资源中才能生效。
```

```
网格和动画文件
	其实是顶点和蒙皮骨骼数据的大型数组，可以应用各种技术最小化文件大小，同时使其外观形似，却不完全相同。
	减少多边形数量
		由于不能使用Skinned Mesh Renderer对对象进行批处理，这是减少动画对象的CPU和GPU运行时开销的好方法之一。
		这是最简单，直接的
	调整网格压缩
		Unity提供了Off Low Medium High压缩设置
		增加设置，把浮点型转换为固定值，降低顶点位置，法线方向的精度，简化顶点颜色信息
		这对包含许多彼此相邻的小部件，（栅栏，栅格）有明显影响。
		程序生成网格可以通过MeshRenderer的Options方法来实现相同类型的压缩。
		OtherSettings有全局设置，影响网格数量VertexCompression OptimizeMeshData
		VertexCompression：如果想要精确的法线数据（照明），但不关心位置数据，可以用这个
		OptimizeMeshData：剔除该网格当前使用的材质所不需要的数据，如果网格包含切线信息，但着色器不需要，Unity
			将再构建期间忽略
		减少了磁盘占用，却需要花费更多时间解压缩数据
	Read-Write Enabled
		禁用-从内存中丢弃原始网格数据
		如果只使用网格的等比缩放版本，则禁用该选项会节省运行时内存
		如果网格经常在运行时以不同缩放出现，需要将网格原始数据保存在内存中，因此要启用选项
	考虑烘焙动画
		烘焙动画意味着，不需要插值和蒙皮数据，就可以有效地将每帧每个顶点的每个位置采样并硬编码到网格/动画文件中。
		蒙皮数据需要惊人的存储空间，如果存储大量顶点信息比蒙皮数据更便宜，就适合使用烘焙
	合并网格
		相当于手动执行静态批处理
		注意，如果网格的任何单个顶点在场景可见，那么整个对象将作为整体进行渲染。
		如果网格在大部分时间只是部分可见，这将浪费大量处理时间。
		如果可以用静态批处理，就不要合并网格。
```

```
AssetBundle Resource

ResourceSystem在原型建立阶段和项目早期阶段很有用
专业的项目应该支持AssetBundleSystem
ResourceSystem将所有资源都合并到一个大型序列化文件二进制数据blob中
其中包含一个索引列表，列表数据越多，越难以管理，需要长时间来构建
复杂度为Nlog(N) 需要警惕N的值
很难基于每个设备提供不同的素材数据，而AssetBundle很容易实现这一点
AssetBundle可用于为App提供小型的，定期的自定义内容更新，
ResourceSystem需要完全替换整个APP
二者都提供加载 异步加载 卸载数据
AssetBundle还提供了 内容流式传输 内容更新 内容生成和共享
这些可以提高App性能，提供磁盘空间占用更小的App
在开始游戏前和运行过程中下载额外内容，在运行时流式传输素材，
以最小化App的首次加载时间，基于不同平台提供更优化的素材，而不是给用户推送完整程序
AssetBundle缺点：建立和维护更复杂，理解起来更复杂，需要更多的测试
```

---

# 第五章 加速物理

```
<------------------------
FixedUpdate				 |
yield WaitForFixedUpdate |
Internal Physics Update  |
OnTrigger				 |
OnCollision				 |
------------------------->
OnMouse
Update

为了确保对象在固定更新之间平稳移动，物理引擎根据下一次
固定更新之前的剩余时间，在处理当前状态之后，在上一个状态和
应处于的状态之间对每个对象的可见位置进行插值。
尽管它们的物理位置，速度等更新的频率低于渲染频率，这种插值
可以确保对象的移动非常平稳


1 最大允许的事件步长
如果自上次固定更新以来已经过了很长时间，那么固定更新将继续在相同的
固定更新循环中计算，直到物理引擎赶上当前时间，如果上一帧花了100ms用于
渲染，那么物理引擎需要更新5次，由于默认固定更新的时间步长为20ms，在再次
调用Update之前还需要调用五次FixedUpdate方法。
当然，如果在这5次固定更新时有很多物理活动需要处理，例如总共花费了超过20ms
处理它们，那么物理引擎将继续调用第六次更新
因此，如果物理活动较多，固定更新的时间可能比模拟的时间要长，例如：用30ms
来处理一个固定更新，模拟20ms的游戏，就已经落后了。需要它处理更多的时间步长
来尝试跟上，但这会导致它落后的更远，需要处理更多的时间步长。
物理引擎永远无法摆脱固定的更新循环，并允许另一帧进行渲染。这被称为死亡螺旋

为了放置物理引擎在这些时刻锁定游戏，存在允许物理引擎处理每个固定更新的最大时间，
MaximumAllowedTimestep 最大时间步长
如果当前一批固定更新的处理时间太长，则它将放弃进一步的处理，直到下一次渲染更新完成。
这种设计允许渲染管线至少将当前的状态进行渲染，并允许用户输入以及游戏逻辑在物理引擎
出现异常的罕见时刻做出一些决策


2 物理更新和运行时变化
当物理引擎以给定的时间步长处理时，它必须移动激活的刚体对象，检测新的碰撞，并调用碰撞回调
Unity文档明确指出，应该在FixedUpdate和其他物理回调中处理刚体对象的更改，原因正是如此。
这些方法与物理引擎的更新频率紧密耦合，而不是游戏循环的其他部分，如Update

这意味着，诸如FixedUpdate和OnTriggerEnter的回调函数是安全更改Rigidbody的位置，而诸如Update
和WaitForSeconds WaitForEndOfFrame的协程则不是。
忽略这一建议可能会导致意想不到的物理行为，因为在物理引擎有机会捕获和处理所有这些对象之前，
可能会对同一个对象进行多次更改。

对Update回调中的对象应用力或脉冲而不考虑这些调用是非常危险的。
例如，在玩家按住一个键时每次Update应用10N的力，会导致两个不同设备之间的合成速度完全不同于在
固定更新中执行相同的操作，因为我们不能依赖Update调用的次数是一致的。但是，在FixedUpdate回调中
这样做会更加一致。因此，必须确保在适当的回调中处理所有与物理相关的行为，否则可能会引入一些特别令人困惑
很难重现的游戏漏洞

从逻辑上讲，在任何给定的固定更新迭代中花费的时间越多，在下一次游戏逻辑和渲染过程中的时间就越少
由于物理引擎几乎没有任何工作要做，而且FixedUpdate后台处理任务。
然而，在某些游戏中，物理引擎可能在每次固定更新期间执行大量的计算。
这种物理处理时间上的瓶颈会影响帧率，导致它在当物理引擎负担越来越大的工作负载时极具下降。
基本上，渲染管线将尝试正常进行，但每当需要进行固定更新时（物理引擎的处理时间很长）
渲染管线在帧结束之前几乎没有时间生成当前画面，导致突然的停顿。还要加上物理引擎过早停止的视觉效果
，因为到达了MaximumAllowedTimestep。所有这些加起来会产生非常糟糕的用户体验。

因此，为了保持平滑，一致的帧率，需要通过最小化物理引擎处理任何给定时间步长所需的时间，来为渲染释放
尽可能多的时间，这适用于最佳情况（没有移动）和最坏情况（所有对象同时于其他对象发生碰撞）
可以在物理引擎中调整一些与时间相关的特性和值，以避免这些性能缺陷。
```

```
5.1.2 静态碰撞器和动态碰撞器

动态碰撞器只意味着GameObject包含Collider组件和Rigidbody组件
物理引擎会将该碰撞器视为带有包围物理对象的立体

没有附加Rigidbody组件的碰撞器称为静态碰撞器。这种碰撞器有效地起到了无形屏障
的作用，动态碰撞器可以碰到这些屏障，但是静态碰撞器不会做出相应。
把没有Rigidbody组件的碰撞体当成无穷大的质量。

物理引擎自动将两种碰撞器分为两种不同的数据结构，每种结构都经过优化以处理现有碰撞器的类型。
这有助于简化未来的处理任务。例如：无法解析两个静态碰撞器之间的碰撞和脉冲。
```

```
5.1.3 碰撞检测

Rigidbody的CollisionDetection有三种设置
Discrete离散
Continuous连续
ContinuousDynamic连续动态

连续碰撞检测：从当前时间步长的起始和结束位置插入碰撞器，并检查在这个时间段中是否有任何碰撞。
代价是CPU开销显著高于离散碰撞检测。

Continuous设置仅在给定碰撞器和静态碰撞器直接启用连续碰撞检测。
与动态碰撞器之间仍旧使用离散碰撞检测。

ContinuousDynamic设置使碰撞器与所有静态和动态碰撞器之间能够使用连续碰撞检测。
最耗时。
```

```
5.14 碰撞器类型

3D: Sphere Capsule Box Mesh
2D:	Circle Box Polygon

两种不同的网格碰撞器 Convex凸 Concave凹
凹形至少有一个大于180度的内角。
两种网格碰撞器都使用MeshCollider组件，是使用Convex复选框切换的

碰撞器组件还包含IsTrigger属性，允许将它们视为非物理对象。
称为触发体积。Trigger Volume
碰撞器和碰撞器之间 OnCollisionEnter OnCollisionStay OnCollisionExit
碰撞器和触发器之间 OnTriggerEnter OnTriggerStay OnTriggerExit
```

```
5.15 碰撞矩阵

只有32个层
静态碰撞器是个例外，因为都不响应物理，尽管仍然受到OnCollision回调
```

```
5.1.6 Rigidbody激活和休眠状态

现代物理引擎的优化技术。
Unity的3D和2D物理引擎都是通过评价质量归一化动能来工作的。
如果物体的速度短时间内没有超过某个阈值，那么物理引擎将假设物体
在经理新的碰撞或施加新的力之前不需要再次移动。
Edit|Project Setting|Physics|Sleep Threshold可以修改这个阈值。
```

```
5.1.7 射线和对象投射
```

```
5.1.8 调试物理

物理错误通常分为两类：
	本来不该碰撞的一对对象碰撞了
	本来应该碰撞的一对对象没有碰撞
但是在事实发生之后，发生了意想不到的事情。
前一种情况通常更容易调试
	碰撞矩阵的错误，射线Layer不正确，对象碰撞器大小或者形状错误
后一种情况往往更难解决，因为有三大问题：
	确定哪个碰撞对象导致了问题
	在解决之前确定碰撞的条件
	重现碰撞
Profiler可以得到CPU活动在不同类型隔离的所有刚体和刚体组上花费的量
	包括动态碰撞器，静态碰撞器，运动对象，触发体积，约束（用来模拟铰链）和触点
	2D包括更多信息，包括睡眠和活动刚体的数量，处理时间步长的时间。
Physics Debugger可以更好的了解哪些对象相互碰撞。但是对确定问题的条件和复现问题没有太大帮助。
	对于剩下的问题，通常需要在OnCollisionEnter和OnTriggerEnter回调中打断点。并逐步调试。记录日志。

另一个令人头疼的问题是，试图重现物理问题。由于用户输入(通常在Update)和物理行为(通常在FixedUpdate)
之间的非确定性。重现冲突始终是一个挑战。
尽管物理时间步长的发生具有相对的规律性，但是模拟在一个会话和下一个会话之间的每个Update上都有不同计时。
即使记录了输入并自动重放场景，尝试在对应时刻用记录的输入，每次也不会完全相同。得不到完全相同的结果。

可以将用户输入放进FixedUpdate，这种移动会有些帮助。
然而可能导致输入延迟，因为在物理引擎响应被按下的键之前，需要等待0~20ms。
如跳跃或激活行为这样的即时输入，通常为了避免按键丢失，最好总在Update中处理。
如果试图在FixedUpdate时读取按键事件，将永远不知道用户按下了键，除非在这两个帧之间恰好发生了物理时间步长。
可以用输入缓冲/跟踪系统，但是如果仅仅为了调试，不值得。

经验和坚持是调试物理问题唯一的好方法。
```

```
5.2 物理性能优化

不一定提高内存或CPU使用率，可能降低物理引擎的不稳定性

5.2.1 场景设置
1 缩放
	缩放尽可能接近 1:1:1，默认重力-9.81，缩放过大会导致重力移动物体的速度比预期慢很多，
	缩放太小会使它们看起来下降太快。
	虽然可以修改重力强度，但是浮点数在接近0时更精确。因此还是最好保证缩放1:1:1

2 位置
	尽可能接近世界空间的0,0,0位置，有更好的浮点数精确度，提高模拟的一致性。
	走了数万米，会产生奇怪的物理行为。

3 质量
	最重要的是质量的相对差异，这样，物理碰撞看起来可行，而不会对物理引擎施加过大压力。
	不要使用太荒谬的超大质量。
	理想情况，质量保持在1.0左右，最大相对质量比在100左右。
	如果质量差太多，巨大的冲量造成突然的速度变化，导致不稳定的物理现象和浮点精度的潜在丢失。

	无论将重力1视为香蕉的质量和军舰的质量都不重要。不需要调整重力来补偿。
	重要的是给定物体在下落时所受的空气阻力。
	因此，为了获得逼真的行为，可能需要为这些对象自定义drag属性，或者基于每个对象自定义重力。
	例如，可以禁用use Gravity，并在FixedUpdate应用自己的重力。

5.2.2 适当使用静态碰撞器
	物理引擎自动生成两个单独的数据结构，分别包含静态碰撞器和动态碰撞器。
	遗憾的是，如果运行时将新对象引入静态碰撞器数据结构，那么必须重新生成它。
	类似于为静态批处理调用StaticBatchingUtility.Combine()
	这可能导致显著的CPU峰值。在游戏中避免实例化新的静态碰撞器是至关重要的。

	此外，仅移动，旋转或缩放静态碰撞器也会触发此过程。
	如果碰撞器希望在不与其他物体发生物理碰撞的情况下移动，应该加入Rigidbody并开启Kinematic
	运动学的动态碰撞器，仍旧可以通过Rigidbody施加力移动。但不会被撞击它的物体做出反应。

5.2.3 恰当使用触发体积
	OnCollisder回调提供了精确的碰撞位置和接触法线。
	OnTrigger没有提供
	因此，不应该使用触发体积对碰撞做出反应。
	触发体积最适用于：当物体进入离开特定区域。
	如果触发体积碰撞确实需要相交信息，常见的接近方法是以下任一操作。
	1 通过将触发体积和碰撞对象的质量中心之间的距离减半，生成粗略估计的接触点
		假设它们的大小大致相等
	2 从触发体积的中心执行射线发射到碰撞对象的质量中心
		当两个对象都是球体时效果最好
	3 创建一个非触发体积对象，给它一个无穷小质量，并在碰撞时立即摧毁它

	当然每个方法都有缺点：有限的精度，碰撞时额外的CPU开销，额外的场景设置。
	但是紧要关头可能有用。

5.2.4 优化碰撞矩阵
	仅使用必要的碰撞，使用了BroadPhase Culling宽相位剔除

5.2.5 首选离散碰撞检测
	离散碰撞检测的消耗相当低，因为只传递一次对象并在附近的对象对之间进行一次重叠检查。
	连续碰撞检测的消耗比离散碰撞检测高一个数量级。
	连续动态碰撞检测的消耗比连续碰撞检测高一个数量级。

	绝大多数对象应该采用离散碰撞检测，如果希望确保玩家不会从游戏世界掉落，或者穿墙，
	可用用连续碰撞检测。
	只有在希望捕捉快读移动的动态碰撞器对之间的碰撞，才应该使用连续动态碰撞检测。

5.2.6 修改固定更新帧率
	有时，离散碰撞检测不够好，全部用连续碰撞检测太昂贵。
	可以自定义物理时间步长，为离散碰撞检测系统提供更好的捕获此类碰撞的机会。

	减小该值，增加频率，将迫使物理引擎更频繁地进行处理。从而使其更容易通过离散
	碰撞检测捕获碰撞。 当然这会增加CPU成本。
	增大该值会降低对象移动的最大速度，而物理引擎无法再通过离散碰撞检测捕获碰撞。
	物理行为不再像现实。
	因此，改变时间步长后，大量测试非常重要。将一些高速对象相互抛向对方，验证结果是否可以接受。

	连续碰撞检测应该作为最后的手段来抵消我们观察到的一些不稳定性。
	由于连续碰撞检测的开销，这也有可能导致比开始时更严重的性能问题。
	需要验证好处是否大于成本。

5.2.7 调整允许的最大时间步长
	如果物理引擎的计算时间经常超过允许的最大时间步长，将导致一系列奇怪的物理行为。
	刚体会突然减速或停止，这种情况下，很明显需要从其他角度优化物理行为。
	阈值将防止游戏在物理处理过程的峰值中完全卡住。
	默认最大值0.333秒，如果超过该值，帧率会显著下降。
	如果觉得有必要更改默认值，显然物理工作负载有大问题，因此建议无可奈何时才更改此值。

5.2.8 最小化射线发射和边界体积检查
	所有射线都非常有用，但是消耗较大，特别是CapsuleCast和SphereCast。
	应该避免在Update或者协程中定期调用。
	只在脚本关键帧调用。
	如果在场景中使用持续的线，射线区域，效果碰撞区域，并且对象相对静止，那么使用简单的触发体积。
	如果不能进行此类替换，且确实需要使用这些方法进行持久的投射检查，那么应该使用层遮罩来最小化每个投射的
	处理量。就是LayerMask

	对于Physics.RaycastHit()来说，使用LayerMask无所谓，因为只为射线和第一个与之碰撞的对象提供碰撞信息。

5.2.9 避免复杂的网格碰撞器
	球体 胶囊体 立方体 凸格 凹格 消耗依次增大
	一对凸格碰撞比两个基本体消耗多一个数量级
	两个凹格碰撞更近复杂
	两个物体都移动比一动一静更复杂
	球体比立方体更简单。
	1 用基本体近似模拟复杂形状
		使用多个基本体拼接
	2 用简单的网格碰撞器
		简化网格碰撞器

5.2.10 避免复杂的物理组件
	TerrainCollider Cloth WheelCollider
	在某些情况下比所有基础碰撞器甚至网格碰撞器的消耗都要高几个数量级
	如无必要，勿增实体
	地形：如果玩家永远不会接近的距离内有地形物体，不为它们使用TerrainCollider
	Cloth：应当考虑在低质量环境下运行时，在没有这些组件的情况下实例化不同的对象，或者
		简单的用布料行为的动画
	WheelCollider：尽量少用Wheel碰撞器，拥有四个以上车轮的大型车辆可以仅用四个车轮模拟
		附件车轮仅仅用图形表示

5.2.11 使物理对象休眠
	许多刚体大部分时间都在休眠，但是游戏中刚体数量增加一倍，总成本可能指数形式增加。
	每次引入新的物理对象，都会导致意外的性能成本。

	运行时修改Rigidbody的任何属性，例如mass drag useGravity会重新唤醒对象。
	如果经常改变这些值（比如物体大小和质量随时间变化）它们回比正常情况更近活跃。
	所以，如果能用自定义重力解决，应该尽量避免每次固定更新都应用重力，否则物体无法休眠。
	可以检测 velocity.sqrMagnitude 在非常低时，手动禁用自定义重力。

	休眠的对象有产生岛屿效应的危险。当大量刚体互相接触，休眠变成岛屿。
	但是它们互相接触，一旦被唤醒，将产生链式反应。一瞬间产生CPU峰值。
	最好通过降低场景的复杂性避免该情况。
	如果无法做到，可以寻找方法来检测岛屿的形成，战略性销毁其中一些，以防产生大型岛屿。
	在所有刚体之间进行定期的距离比较，也产生消耗。
	因为物理引擎在 广泛阶段剔除期间，已经执行了这样的检查，但是Unity没有公开这些数据。
	任何解决这个问题的方法都取决于游戏的设计方式：
	例如，一个游戏要求玩家将大量物理体移动到某个区域，（羊赶进围栏）
	可以在羊到位后删除碰撞器，将物体锁定到其最终目的地，减去物理引擎的工作量。

	休眠优劣兼有，它们可以节省大量处理能力，但是同时唤醒又带来性能成本。
	应该尽可能限制这些情况，避免形成集群。

5.2.12	修改处理器迭代次数
	关节 弹簧是相当复杂的模拟，内部的运动约束必须求解必要的数学方程。并多次迭代法求解。
	因此，必须权衡最大迭代次数和准确性。最大迭代次数Solver Iteration Count
	在Edit|Project Settings|Physics|Default Solver Iterations

	大多数情况下，六次迭代的默认值完全可接受。
	然而，游戏如果包含非常复杂的关节Joint系统，就可能希望增加迭代次数。
	一些项目希望减少次数来避免过高计算。
	更改这个值后必须测试。

	可以在运行时用 Physics.defaultSolverIterations属性修改这个值，但这样做不会影响之前创建的刚体
	如果有必要，可以在刚体构造后修改Rigidbody.solverIterations属性修改

	如果布娃娃经常不稳定，违反物理规则，应该考虑逐渐增加迭代次数。
	如果有一个连接点非常不稳定，影响后面节点，可以在
	Edit|Project Settings|Physics|Default Solver Velocity Iterations
	增大该值，将关节控制在合理的速度

	可以在运行时通过 Physics.defaultSolverVelocityIterations修改，同理不会影响之前创建的刚体，
	Rigidbody.solverVelocityIterations属性

	2D物理对迭代次数的设置叫做 Position Iterations 和 Velocity Iterations

5.2.13 优化布娃娃
	1 减少关节和碰撞器
		GameObject|3D Object|Ragdoll 默认13个不同的碰撞器
		骨盆 胸部 头部 每条手臂两个碰撞器 每条大腿三个碰撞器

		每个肢体一个碰撞器可以大大降低成本，需要重新分配质量值
		因为默认13个碰撞器将质量分布在13个位置上，手动修改成7个需要修改质量
	2 避免布娃娃间碰撞
		简单使用Layer
	3 更换 禁用 移除不活跃的布娃娃
		一旦落地，就不需要再作为可交互对象留在游戏中
		可以禁用 销毁
		可以替换成7碰撞器布娃娃
		Rigidbody.IsSleeping()观察每个布娃娃是否休眠
	4 确定何时使用物理
		提升性能最明显的方式是避免使用物理。
			比如，检查Y轴判定区域而不是使用物理碰撞器。
			模拟流星雨，可以不需要物理，只改变位置。
		反过来，可以用物理提升性能。
			用物理引擎判断最近拾取武器。Physics.OverlapSphere
		从场景中删除不必要的物理工作，
		或者用物理替换脚本执行时代价高昂的行为。
```

---

# 第六章 动态图形

```
1 CPU GPU起作用的部分
2 如何确定是否受到CPU GPU的限制
3 优化技术和特性：
	GPU实例化
	LOD和其他筛选组
	遮挡剔除
	粒子系统
	UI
	着色器优化
	照明和阴影优化
	特定移动设备渲染增强


6.1 管线渲染

CPU		游戏-->图形API-->硬件取动
							   |
GPU前端	光栅化器<--图元装配<--顶点着色器
		|
GPU后端	像素（片元）着色器-->帧缓冲区

6.1.1 GPU前端
	前端是指渲染过程中GPU处理顶点数据的部分。
	从CPU中接收网格数据，并发出DrawCall
	然后GPU从网格数据中收集顶点信息，通过顶点着色器进行传输，
	对数据按一比一的比例进行修改和输出。
	之后，GPU得到一个需要处理的图元列表（三角形）
	接下来，光栅化器获取这些图元，确定最终图形的哪些像素需要绘制。
	并根据顶点的位置和当前相机视图创建图元。
	这个过程中生成的像素列表称为片元，将在后端进行处理。

	顶点着色器用来确定想要的输入数据和数据处理方式，并向光栅化器输出一组信息来生成片元。
	这也是进行曲面细分处理的地方，曲面细分由几何着色器（有时也称曲面细分着色器）处理，
	和顶点着色器类似，几何着色器也是shader
	不同的是，几何着色器可以1对多的方式输出顶点。

6.1.2 GPU后端
	每个片元都通过片元着色器（像素着色器）来处理。
	片元着色器往往涉及更复杂的活动，例如深度测试，alpha测试，着色，纹理采样
	光照，阴影以及一些可行的后期效果处理。
	之后这些数据绘制到帧缓冲区。
	正常情况下，图形API默认使用两个帧缓冲区。
	只要程序还在渲染，就会为每个网格，顶点，片元和帧重复这个从调用图形API到切换缓冲区的处理流程。

	1 填充率
	指的是GPU绘制片元的速度。
	然而，这仅仅包含在给定的片元着色器中通过各种条件测试的片元。
	片元只是一个潜在的像素，只要未通过任一测试，则会被丢弃。
	这可以大大提高性能，管线渲染跳过昂贵的绘制步骤，开始处理下一个片元。
	z-测试，检查较近对象的片元是否以及绘制在同样的片元位置，
	z指的是从相机的视角观察的深度维度。
	如果已被绘制，则丢弃当前片元。
	如果没有绘制，则在目标像素上绘制，小号一个填充量。
	假设该过程用于成千上万的重叠对象，每个对象都可能生成成百上千个片元，
	这导致每帧都要处理上百万个片元，因为主摄像机的视角上，片元可能重叠。
	尽可能跳过这些绘制过程将节省大量渲染成本。
	填充率会被一些高级渲染技术消耗，例如阴影和后期效果处理需要提取同样的片元数据，
	在帧缓冲区中执行自己的处理。
	由于渲染对象的顺序，我们总是会重绘一些相同的像素，称为过度绘制，这是衡量填充率是否有效使用的一个重要指标。

	过度绘制
	通过使用叠加alpha混合和平面着色来渲染所有对象，过渡绘制的多少就可以直观地显示出来。
	过渡绘制多的区域将显示的更加明亮。
	过渡绘制得越多，覆盖片元数据所浪费的填充率就越多。
	注意：实际上有几种不同的队列用于渲染，可分为两种类型：不透明队列和透明队列。
	不透明队列中渲染的对象可以通过z-测试剔除片元，
	然而，在透明队列中渲染的对象不能这样做。
	所有Unity UI对象通常都在透明对象中渲染，这也是过渡绘制的主要来源。

	2 内存带宽
	GPU后端的另一个潜在瓶颈来自于内存带宽
	只要从GPU VRAM的某个部位将纹理拉入更低级别的内存中，就会消耗内存带宽。
	这通常发生在纹理采样时，片元着色器尝试选择匹配的纹理像素
	GPU包含多个内核，每个内核都可以访问VRAM的相同区域，还有一个小得多的本地纹理缓存，
	来存储GPU最近使用的纹理。
	如果纹理已经存在于本地纹理缓存中， 那么非常快
	如果纹理缓存丢失，则需要从VRAM中提取纹理信息，会消耗一定可用内存带宽
	如果在内存带宽方面遇到瓶颈，GPU将继续获取必要的纹理文件，但是整个过程受到限制。
	因为纹理缓存将等待获取数据后，才会处理给定的一批片元。
	GPU无法及时将数据推回到帧缓冲区，整个过程被阻塞，帧率降低。

	如何对内存带宽进行合理使用需要估算。
	例如：每个内核的内存带宽为每秒96GB，目标帧率是60fps，在到达内存带宽瓶颈前，
	GPU每秒可提取1.6GB (90/60)的纹理数据。
	请注意：这个值并不是游戏可在项目，CPU RAM或者VRAM中包含的纹理数据的最大限制。
	其实，这个指标限制的是一帧中可以发生的纹理交换量。
	同一纹理在一帧内可以被来回拉动多次，主要取决于着色器使用它们的次数，对象渲染的顺序以及纹理采样的频率。
	由于纹理的缓存空间是有限的，因此只有少数对象可以占用千兆字节的内存带宽。
	如果着色器需要大量纹理，很可能造成缓存丢失，从而造成内存带宽瓶颈。
	如果多个对象需要不同的高质量纹理和多个二级纹理映射（法线映射，发散映射等）
	那么在非批处理模式下，瓶颈很容易被触发。
	在这种情况下，纹理缓存无法对单个纹理文件挂起足够的时间，来支撑下一个渲染过程的采样。

6.1.3 光照和阴影
	光照和阴影，通常在片元着色器的多个过程中处理，对于多个光源中的每个都处理一次，最后将结果进行合并。
	阴影信息的收集需要多个过程，首先为场景设置阴影投射器和接收器，分别用来投射和接受阴影。
	然后，每次渲染阴影接收器时，GPU都会从光源的角度将任何阴影投射器对象渲染成纹理，目标是收集每个片元的距离信息。
	对阴影接收器进行同样的动作，除了阴影投射器和光源重叠的片元外，GPU可将片元渲染得更暗，因为这类片元位于阴影投射器产生的阴影下。
	之后，这些信息变成附加的纹理，称为纹理阴影（shadowmap）。当从主机相机视角渲染时，它们被混合在阴影接收器表面。
	这使得位于光源和给定对象之间的某些位置变得更暗。Lightmap的创建过程与之类似，其为场景中的很多静态部分预生成光照信息。
	在管线渲染的所有过程中，光照和阴影往往会消耗大量资源。
	我们需要为每个顶点提供法矢方向（指向远离表面的矢量），来确定光线如何从表面反射出去，同时需要附加的顶点颜色属性，来应用一些额外的着色。
	这为CPU前段提供了更多要传递的信息。由于片元着色器需要多次传递信息来完成最终的渲染，因此后端在填充率（大量需要绘制，重绘，合并的像素）
	和内存带宽（为Lightmap Shadowmap拉入和拉出的额外纹理）方面将处于繁忙状态。
	这就是为什么和其他渲染特性相比，实时阴影异常昂贵，在启用后会显著增加DrawCall数的原因。
	然而，光照和阴影可能是游戏美术和设计中两个最重要的部分，常常值得花时间来满足。
	优秀的光照和阴影能化腐朽为神奇，因为专业的渲染如同魔法，可以让场景的视觉效果更有吸引力。
	甚至是低面美术风格（例如手游纪念碑谷）在很大程度上依赖良好的光照和阴影轮廓，以便玩家区分不同的物体，并创造良好的视觉体验。

	Unity提供了多种光照和阴影，包括实时光照和阴影，Lightmapping静态光照。
	这里有许多选项，如果不小心，很多事情可能导致性能问题。
	渲染有两种不同的方式，前向渲染和延迟渲染，它们对光照的性能都有很大影响。
	这些渲染选项的设置可以在 Edit ProjectSettings Player OtherSettings Rendering找到

	前向渲染
		是场景中渲染灯光的传统方式。在向前渲染过程中，每个对象都通过同一个着色器进行多次渲染。
		渲染的次数取决于光源的数量，距离和亮度。
		Unity优先考虑对对象影响最大的定向光源组件，并在基准通道中渲染对象，作为起点。
		然后通过片元着色器使用附近几个强大的点光源组件对同一个对象进行多次重复渲染。
		每一个点光源都在每个顶点的基础上进行处理，所有剩余的光源都通过“球谐函数”技术被压缩成一个平均颜色。
		为了简化这些行为，可以将灯光的RenderMode调整为Not Important，并在
		Edit ProjectSettings Quality PixelLightCount中修改参数。
		这个参数限制了前向渲染采集的灯光数量，但当RenderMode设置为Import时，该值将被任意灯光数覆盖。
		因此，应该慎重使用这个设置组合。
		可以看出，使用前向渲染处理带有大量点光源的场景，将导致DrawCall数量呈爆炸式增长，
		因为需要配置的渲染状态很多，还需要着色器通道。

	延迟渲染
		延迟渲染又称为延迟着色，是一项在GPU上使用了十年多的技术，但一直没能完整取代向前渲染。
		因为涉及一些手续，移动设备对它的支持也有限。
		延迟着色这么命名，是因为实际的着色发生在处理的后期，也就是说延迟到后期才发生。
		它的工作原理是创建一个几何缓冲区，称为（G缓冲区）
		在该缓冲区中，场景在没有任何光照的情况下进行初始渲染。
		有了这些信息，延迟着色系统可以在一个过程中生成照明配置文件。
		从性能的角度看，延迟着色的结果让人印象深刻，因为它可以产生非常好的逐像素照明，而且几乎不需要DrawCall
		延迟着色的一个缺点是无法独立管理抗锯齿，透明度和动画人物的阴影应用。
		在这种情况下，前向渲染技术就作为一种处理这些任务的备用选项，因此需要额外的DrawCall来完成。
		延迟着色技术的一个更大的问题是它往往需要高性能，昂贵的硬件来支持，且不能用于所有平台。
		因此很少有用户能使用它。

	顶点照明着色 传统
		从技术上讲，照明的方法不止有两种。
		目前仅存的两种是 顶点照明着色 和 很原始，功能粗放的延迟渲染版本。
		顶点照明着色是光照的大规模简化处理，因为光照是按顶点处理而不是按像素处理。
		换句话说，整个表面都是基于射入灯光的颜色进行统一着色，而不是通过单个像素对表面进行混合照明着色。
		许多甚至全部3D游戏都不会采用这种传统的技术，因为缺乏阴影和合适的照明功能支持，顶点照明着色要实现
		深度的可视化非常困难。
		该技术主要应用在一些不需要使用阴影，法线映射和其他照明功能的简单2D游戏。

	全局照明
		Global Illumination GI，是烘焙Lightmapping的一种实现。
		Lightmapping类似于阴影技术创建的Shadowmap，其为每个表示额外照明信息的对象生成一个或多个纹理。
		然后在片元着色器的光照过程中应用于对象，以模拟静态光照效果。
		这些Lightmap和其他形式光照的最大区别是，Lightmap是在编辑器中预先生成或烘焙的，并打包到游戏的构建版本中。
		这确保在游戏运行时不需要不断地重新生成这些信息，从而节省大量的DrawCall和重要的CPU活动。
		由于可以烘焙这些数据，因此有足够的时间来生成高质量的Lightmap（当然，代价是需要处理所生成的更大量的纹理文件）
		由于这些信息是提前生成的，因此无法响应游戏中的实时活动，所以在默认情况下，任何Lightmapping信息只应用于场景中
		生成Lightmap时出现的静态对象。
		但是，可以将LightProbe添加到场景中，以生成一组额外的Lightmap纹理，这些纹理可以应用到附近移动的动态对象，
		使这些对象能够从预生成的光照中受益。
		这种方式不追求完美的像素精度，在运行时还要为额外的LightProbe和内存带宽的数据交换提供磁盘空间，
		但是它生成了一个更可信的，更合适的灯光配置文件。

		多年来，人们开发了多种生成Lightmap的技术，Unity从发布以来就使用两种不同的解决方案。
		全局照明是在Lightmapping后最新一代的数字技术，它不仅计算光照如何影响给定对象，还计算光照如何从附近的表面反射回来，
		允许对象影响它周围的照明配置文件，从而提供非常真实的着色效果。
		这种效果由一个称为Enlighten的内部系统来计算。该系统既可以创建静态Lightmap，也可以创建预计算的实时全局照明，
		它是实时和静态阴影的混合，支持在没有昂贵的实时照明效果下模拟一天中的时间效果。（太阳光的方向随着时间变化）

		生成Lightmap的一个典型问题是，在当前设置下Lightmap从生成到获得视觉回馈所需的时间很长，因为Lightmapper经常尝试
		在一个过程中生成包含全部细节的Lightmap。如果用户尝试修改这些配置，则必须取消并重启整个作业。
		为了解决这个问题，Unity技术实现了渐进式的Lightmap，渐进式的Lightmap可随着时间的推移逐步执行Lightmapping任务，
		还允许计算时对配置信息进行修改。这使场景中Lightmap的显示过程变得越来越详细，因为它是后台运行，另外允许在运行时修改
		某些属性而不需要重新启动整个工作。这提供了准实时的回馈机制，极大改进了生成Lightmap的工作流程。

	多线程渲染
		大多数系统默认都开启多线程渲染功能，台式电脑，终端，Android，IOS都支持，此书编写时WebGL还不支持
		对于场景中的每个对象，渲染过程需要完成三个任务：
		首先，确定对象是否需要渲染（通过视椎剔除技术），
		如果需要，就生成渲染对象的指令（因为单个对象的渲染可能产生数十个指令）
		最后调用响应的图形API将指令发送到GPU。

		在没有多线程渲染的情况下，这些任务都在CPU的主线程上执行，那么主线程上的任何活动都将成为渲染的关键路径中的节点。
		多线程渲染启动时，渲染线程会将指令推送到GPU，其他任务（如剔除和生成指令）则分散在多个工作线程中。
		这种模式可以为主线程节省大量的CPU周期，而其他的绝大部分任务都是在CPU的主线程中执行，例如物理和脚本代码。

		多线程渲染一旦启用，将影响CPU的瓶颈。
		在未启用该特性时，主线程将执行为命令行缓冲区生成指令所需的所有工作，
		这意味着在其他地方提升的性能可以释放出来，让CPU生成指令。
		但是，当多线程渲染启动后，大部分的工作负载都将被推送到独立的线程中，这意味着通过CPU提升主线程对渲染性能的影响很小。

	低级渲染API
		Unity通过CommandBuffer类对外提供渲染API。
		这允许通过C#代码发出高级渲染命令，来直接控制管线渲染，例如采用特定的材质，使用给定的着色器渲染指定的对象，
		或者绘制某个程序几何体的N个实例。
		这种定制化的功能不如直接调用图形API那么强大，但是对Unity开发人员来说，定制独特的图形效果是朝正确的方向迈出的一步。
		如果需要更直接地控制渲染，例如想要直接给OpenGL DirectX Metal调用图形API，就需要创建一个本地插件，挂接到Unity的管线渲染，
		设置为特定渲染事件发生时的回调，类似于MonoBehaviours挂载到Unity主引擎。
		对于Unity用户来说，这是高级主题，但随着我们对渲染技术的了解，这非常有用。


6.2 性能检测问题

	6.2.1 分析渲染问题
		1 CPU生成指令产生非常多的DrawCall，由于渲染对象简单，GPU工作非常少
			CPU受限，瓶颈在CPU中。
			注意：分析独立程序
		2 通过性能分析器分析GPU受限的程序有点困难
			主要是CPU等待GPU Gfx.WaitForPresent
			分析器上CPU，GUP时间类似，实际上CPU在等GPU，GUP工作负载大
			为了执行准确的GPU受限的性能分析测试，应该在
			Edit|Project Settings|Quality|Other|VSyncCount中禁用VerticalSync，
			否则测试数据将受到干扰。
	6.2.2 暴力测试
		分析器无法确定，或者GPU受限需要确定管线渲染的瓶颈，就应该使用暴力测试方法。
		即在场景中去除指定的活动，并检查性能是否大幅提升。
		如果一个小的调整导致性能大幅提升，说明找到了瓶颈所在的重要线索。

		对于CPU受限，最明显的暴力测试就是降低DrawCall来检测性能是否突然提升。
		然而这种方式通常不太可能实现，因为我们已经通过静态批处理，动态批处理，混淆等技术将DrawCall降到最低。
		这说明可降低的DrawCall范围非常有限。
		但是，可以引入更多的对象或禁用DrawCall优化，故意增加DrawCall，并观察情况是否更糟糕。
		如果是，说明我们已经接近或者到达CPU的限制。

		有两种好的暴力测试方法来测试GPU是否受限，以确定是填充率受限，还是内存带宽受限。
		这两种方法分别是降低屏幕分辨率和降低纹理分辨率。
		填充率受限
		通过降低屏幕分辨率，可以让光栅器生成的片元少很多，并在较小的像素画布上进行转化，以便进行后端处理。
		这将减少应用程序填充率的消耗，为管线渲染的关键部分提供缓冲的空间。
		因此，如果屏幕分辨率降低后，性能突然提高，那么填充率应该是我们首要关注的问题。
		内存带宽上遇到瓶颈
		如果内存带宽遇到瓶颈，降低纹理质量可能会显著提高性能。
		这样会减小纹理的大小，极大降低片元着色器的内存带宽成本，允许GPU更快地获取必要的纹理。
		为了降低全局纹理质量，可以在Edit|ProjectSettings|Quality|TextureQuality
		设置的值为HalfRes QuarterRes EighthRes

	总结
		可以看出，CPU受限的应用程序都有足够的机会来提高性能
		如果从其他活动中释放CPU周期，就可以通过更多的DrawCall来渲染更多的对象，
		当然请记住，每次渲染都将消耗GPU中更多的活动。
		但是，在改进管线渲染的其他部分时，还有一些额外的机会可以间接更改DrawCall计数。
		包括遮挡剔除，调整光照和阴影以及修改着色器。

		与此同时，可能需要一部分暴力测试和进行一些猜测，来确定GPU受限应用程序的瓶颈。
		大部分应用的瓶颈都是填充率和内存带宽，因此应该从这里着手。
		前段程序很少出现瓶颈，至少桌面应用是这样，所以只有验证了其他来源没有问题，才应进行前端检查。
		与片元着色器相比，顶点着色器的影响微乎其微，
		因此前端处理产生问题的真正原因是推送了太多的几何体，或几何体过于复杂。
		最后，先确定CPU还是GPU受限，如果是GPU，是前端还是后端受限，是填充率瓶颈还是内存带宽瓶颈。
		有了这些意识，可以应用很多技术提高性能。

6.3 渲染性能的增强
	6.3.1 启用/禁用 GPU Skinning
		第一个技巧
		通过牺牲GPU Skinning来降低CPU或GPU前端的负载。
		Skinning是基于骨骼动画的当前位置变换网格顶点的过程。
		在CPU上工作的动画系统会转换对象的骨骼，用于确定其当前的姿势，
		但动画过程中的下一个重要步骤是围绕这些骨骼包裹网格顶点，以将网格放在最终的姿势中。
		为此，需要迭代每个顶点，并对连接到这些顶点的骨骼执行加权平均。
		该顶点处理任务可以在CPU执行，也可以在GPU前端执行，取决于是否启用GPU Skinning选项。
		Edit|Project Settings|Player Settings|Other Settings|GPU Skinning
		注意，CPU必须将数据传到GPU，并在命令缓冲区为任务生成指令，因此CPU仍然有工作负载。
		禁用GPU Skinning可以减轻GPU负担。但是如果场景有很多网格，GPU Skinning就非常有用，且可以将工作推到空闲的设备上，来设置边界。？不太懂
	6.3.2 降低几何复杂度
		GPU前端技巧。
		有助于减少网格的顶点属性，网格常常包含大量不必要的UV和法线矢量数据，
		因此应该仔细检查网格是否包含这种多余信息。
		应该让Unity优化结构，这样可以在前端内读取顶点数据时最大限度减少丢失缓存的情形。
		我们的目标只是降低实际的顶点数量。
		三种方法，
		1，美术团队手动调整，生成多边形更少的网格，或用网格抽取工具简化网格。
		2，简单地从场景移除网格，但这应该是最后的手段。
		3，实现网格的自动剔除特性，如LOD。
	6.3.3 减少曲面细分
		通过几何着色器进行曲面细分非常有趣，因为曲面细分是一种相对还未充分使用的技术，
		可以真正使图形效果在使用最常见效果的游戏中脱颖而出。
		但也极大地增加了前端处理的工作量。
		除了改进曲面细分算法或者减轻其他前端的负载，来使曲面细分任务有更多的空闲空间外，
		并没有其他简单的技巧可以改进曲面细分。
		不管哪种方式，如果前端遇到瓶颈，却在使用曲面细分技术，
		就应该仔细检查曲面细分是否消耗了大量前端资源。
	6.3.4 应用GPU实例化
		GPU实例化利用对象具有相同渲染状态的特点，快速渲染同一网格的多个副本。
		因此只需要最少的DrawCall。
		这其实和动态批处理一样，只不过不是自动处理的过程。
		实际上，可以将动态批处理看成一种简单的GPU实例化，因为真正的GPU实例化可
		节省更多的资源，并支持通过参数调整实现更多的定制化。
		选中Enable Instancing复选框，可以在材质级别上应用GPU实例化，
		修改着色器代码，就可以引入变化。
		这样，就可以为不同的实例提供不同的旋转，比例，颜色等特性。
		这对于渲染森林和岩石等场景很有用，在这种场景中，可以渲染成百上千个
		有细微差异的网格副本。
		注意，Skinned Mesh Renderer无法应用到GPU实例化，其原因和不能动态使用批处理类似，
		并不是所有的平台和API都支持GPU实例化。
		这个系统比动态批处理更加通用，因为可以更多地控制对象的批处理过程。
		当然，如果以低效的方式进行批处理操作，出错的机会更多，必须谨慎使用。
	6.3.5 使用基于网格的LOD
		LOD （Level Of Detail） 是一个广义的术语，
		指的是根据对象与相机的距离和/或对象在相机中占用的空间，动态地替换对象。
		由于远距离很难分辨低质量和高质量对象之间的差异，一般不会用高质量方式渲染对象。
		LOD最常见的实现是基于网格的LOD：
		可以在场景中放置多个对象，使其成为具有附加LODGroup组件的GameObject的子对象。
		LOD组的目的是从这些对象中生成边界框，并根据相机视野内的边界框大小决定应该渲染哪个对象。
		如果对象的边界框占用当前视图的大部分区域，就启用分配给较低LOD组的网格；
		如果边界框非常小，就是用较高LOD组的网格。
		如果网格太远，可以将其配置为隐藏所有子对象。
		因此，通过正确设置，可以让Unity用更简单的替代品代替网格，或者完全剔除网格，减轻渲染负担。
		这个特性需要花费大量时间才能完全实现：美工必须为同一个对象生成多边形数较少的版本，关卡设计师
		必须生成LOD组，并进行配置和测试，以确保他们不会在相机移近或移远时出现不和谐转换。
		注意：有自动生成LOD网格的工具，这类LOD网格的易用性，质量损失和成本效益的对比值得研究。
		基于网格的LOD会消耗磁盘，占用空间，RAM和CPU：
		替代网格需要捆绑在一起加载到RAM中，并且LODGroup组件必须定期测试相机是否移动到新的位置，以修改LOD级别。
		但管线渲染的优点相当显著。动态渲染较简单的网格，减少了需要传递的顶点数据量，
		并潜在减少了渲染对象时的DrawCall数量，填充率和内存带宽。
		由于要实现基于网格的LOD功能需要牺牲很多，开发人员应该自动假设基于网格的LOD是有益的，避免预先优化。
		过度使用该特性会增加应用程序其他部分的性能负担，并占用开发时间，这一切都是出于偏执。
		只有当我们观察到渲染中出现问题，并且CPU，RAM和开发时间都有空闲时，才是用LOD。
		话虽如此，拥有广阔视野和大量相机运动的场景，可能需要尽早考虑LOD，
		因为增加的距离和大量可见的物体可能会极大地增加顶点数。
		相反，总是在室内的场景，或者相机俯视视角的场景，使用这种技术没有什么好处，因为对象总是与相机保持类似的距离。
		示例包括RTS RealTime Strategy，MOBA Multiplayer Online Battle Arena。

		剔除组 Culling Groups
		剔除组是Unity API的一部分，允许创建自定义的LOD系统，作为动态替换某些游戏或渲染行为的方法。
		希望应用LOD的示例包括
			用较少骨骼的版本替换动画角色，
			应用更简单的着色器，
			在很远的距离上跳过粒子系统生成过程，
			简化AI行为等。
		在其基本的层次上，剔除组系统仅仅指出，物体对相机是否可见，它们有多大，但它在游戏中也有其他用途，
		比如确定玩家是否可以看到某些敌人的据点，或者玩家是否正在接近某些区域。
		剔除组系统还有更广阔的用途，因此值得关注。
		当然，实现，测试和重新设计场景所花费的时间也很多。
	6.3.6 使用遮挡剔除
		减少填充率消耗和过度绘制的最佳方法之一是使用Unity的遮挡剔除系统。
		该系统的工作原理是将世界分割成一系列小单元，并在场景中运行一个虚拟摄像机，
		根据对象的大小和位置，记录哪些单元对其他单元是不可见的（被遮挡）。
		注意：这与视锥剔除技术不同，视锥剔除是当前相机视图之外的对象。
		视锥剔除总是主动和自动进行的。因此遮挡剔除将自动忽略视锥剔除的对象。
		只有在StaticFlag下拉列表下正确标记为 Occluder Static 和 Occludee Static的对象
		才能生成遮挡剔除数据。
		Occluder Static是静态对象的一般设置，它们既能够遮挡其他物体，也能被其他物体遮挡，
		例如摩天大楼或山脉，这些物体可以隐藏其他物体，也能隐藏在其他物体后面。
		Occludee Static是一种特殊情况，例如透明对象总是需要利用它们身后的其他对象才能呈现出来，
		但如果有大的对象遮挡住它们，则需要隐藏它们本身。
		提示：当然，必须为遮挡剔除启用Static标志，所以此功能不适用于动态对象。
		遮挡剔除可以看Overdraw模式下的绘制。
		启用遮挡剔除功能将消耗额外的磁盘空间，RAM和CPU时间。
			需要额外的磁盘空间来存储遮挡数据，
			需要额外的RAM来保存数据结构，
			需要额外的CPU资源来确定每个帧中哪些对象需要被遮挡。
		遮挡剔除数据结构必须正确配置，以创建场景中适当大小的单元，单元越小，生成数据结构所需的时间就越长。
		但是，如果为场景进行了正确的配置，遮挡剔除可以剔除不可见的对象，减少过度绘制和DrawCall数量，来节省填充率。
		注意：即使对象被遮挡剔除，也必须计算其阴影，所以不会节省这些任务的DrawCall数和填充率。
	6.3.7 优化粒子系统
		//todo 168
```

---